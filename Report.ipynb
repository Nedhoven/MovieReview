{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movie reviews predictions with machine learning techniques and natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we investigate Deep Neural Networks (DNN) on the IMDB movie reviews data set to see if we can predict the \"Positive\" or \"Negative\" labels for the reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "import math as math\n",
    "from numpy import asmatrix as arr\n",
    "from imp import reload\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "dataset = tf.keras.utils.get_file(fname=\"aclImdb.tar.gz\",\n",
    "                                  origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
    "                                  extract=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "he dataset consists of IMDB movie reviews labeled by positivity from 1 to 10. The task is to label the reviews as negative or positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all files from a directory in a DataFrame.\n",
    "\n",
    "def load_directory_data(directory):\n",
    "    data = {}\n",
    "    data[\"sentence\"] = []\n",
    "    data[\"sentiment\"] = []\n",
    "    for file_path in os.listdir(directory):\n",
    "        with tf.io.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
    "            data[\"sentence\"].append(f.read())\n",
    "            data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
    "    return pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge positive and negative examples, add a polarity column and shuffle.\n",
    "\n",
    "def load_dataset(directory):\n",
    "    pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
    "    neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
    "    pos_df[\"polarity\"] = 1\n",
    "    neg_df[\"polarity\"] = 0\n",
    "    return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_dataset(os.path.join(os.path.dirname(dataset),\"aclImdb\", \"train\"))\n",
    "test_df = load_dataset(os.path.join(os.path.dirname(dataset), \"aclImdb\", \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training input on the whole training set with no limit on training epochs.\n",
    "train_input_fn =tf.compat.v1.estimator.inputs.pandas_input_fn(train_df, train_df[\"polarity\"], num_epochs=None, shuffle=True)\n",
    "\n",
    "# Prediction on the whole training set.\n",
    "predict_train_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(train_df, train_df[\"polarity\"], shuffle=False)\n",
    "# Prediction on the test set.\n",
    "predict_test_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(test_df, test_df[\"polarity\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_text_feature_column = hub.text_embedding_column(\n",
    "    key=\"sentence\", \n",
    "    module_spec=\"https://tfhub.dev/google/nnlm-en-dim128/1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Behzad\\AppData\\Local\\Temp\\tmplgx5pgbr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Behzad\\AppData\\Local\\Temp\\tmplgx5pgbr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Behzad\\\\AppData\\\\Local\\\\Temp\\\\tmplgx5pgbr', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001AFFF316828>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Behzad\\\\AppData\\\\Local\\\\Temp\\\\tmplgx5pgbr', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001AFFF316828>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# For classification we can use a DNN Classifier \n",
    "estimator = tf.estimator.DNNClassifier(\n",
    "    hidden_units=[500, 100],\n",
    "    feature_columns=[embedded_text_feature_column],\n",
    "    n_classes=2,\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.003))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the estimator for a reasonable amount of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Behzad\\AppData\\Local\\Temp\\tmplgx5pgbr\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Behzad\\AppData\\Local\\Temp\\tmplgx5pgbr\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.72023165, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.72023165, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 54.6431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 54.6431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.43089542, step = 100 (1.833 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.43089542, step = 100 (1.833 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 56.7517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 56.7517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.48981568, step = 200 (1.761 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.48981568, step = 200 (1.761 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 57.3054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 57.3054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5026357, step = 300 (1.745 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5026357, step = 300 (1.745 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 56.8901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 56.8901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4181981, step = 400 (1.759 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4181981, step = 400 (1.759 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 57.0519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 57.0519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.49050504, step = 500 (1.752 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.49050504, step = 500 (1.752 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 55.8363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 55.8363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.38381088, step = 600 (1.792 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.38381088, step = 600 (1.792 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 57.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 57.261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.43899608, step = 700 (1.746 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.43899608, step = 700 (1.746 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 57.6687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 57.6687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.38885882, step = 800 (1.734 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.38885882, step = 800 (1.734 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 56.8613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 56.8613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.34199852, step = 900 (1.758 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.34199852, step = 900 (1.758 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\Behzad\\AppData\\Local\\Temp\\tmplgx5pgbr\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\Behzad\\AppData\\Local\\Temp\\tmplgx5pgbr\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.4121698.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.4121698.\n"
     ]
    }
   ],
   "source": [
    "estimator.train(input_fn=train_input_fn, steps=1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run predictions for both training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-12-11T22:02:08Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-12-11T22:02:08Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Behzad\\AppData\\Local\\Temp\\tmplgx5pgbr\\model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Behzad\\AppData\\Local\\Temp\\tmplgx5pgbr\\model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-12-11-22:02:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-12-11-22:02:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.81904, accuracy_baseline = 0.5, auc = 0.9033435, auc_precision_recall = 0.9043195, average_loss = 0.39515895, global_step = 1000, label/mean = 0.5, loss = 0.39486086, precision = 0.80479974, prediction/mean = 0.5214938, recall = 0.8424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.81904, accuracy_baseline = 0.5, auc = 0.9033435, auc_precision_recall = 0.9043195, average_loss = 0.39515895, global_step = 1000, label/mean = 0.5, loss = 0.39486086, precision = 0.80479974, prediction/mean = 0.5214938, recall = 0.8424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: C:\\Users\\Behzad\\AppData\\Local\\Temp\\tmplgx5pgbr\\model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: C:\\Users\\Behzad\\AppData\\Local\\Temp\\tmplgx5pgbr\\model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-12-11T22:02:16Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-12-11T22:02:16Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Behzad\\AppData\\Local\\Temp\\tmplgx5pgbr\\model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Behzad\\AppData\\Local\\Temp\\tmplgx5pgbr\\model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-12-11-22:02:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-12-11-22:02:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.79792, accuracy_baseline = 0.5, auc = 0.88340956, auc_precision_recall = 0.88426083, average_loss = 0.43033892, global_step = 1000, label/mean = 0.5, loss = 0.4304254, precision = 0.785364, prediction/mean = 0.519606, recall = 0.81992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.79792, accuracy_baseline = 0.5, auc = 0.88340956, auc_precision_recall = 0.88426083, average_loss = 0.43033892, global_step = 1000, label/mean = 0.5, loss = 0.4304254, precision = 0.785364, prediction/mean = 0.519606, recall = 0.81992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: C:\\Users\\Behzad\\AppData\\Local\\Temp\\tmplgx5pgbr\\model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: C:\\Users\\Behzad\\AppData\\Local\\Temp\\tmplgx5pgbr\\model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.8190400004386902\n",
      "Test set accuracy: 0.7979199886322021\n"
     ]
    }
   ],
   "source": [
    "train_eval_result = estimator.evaluate(input_fn=predict_train_input_fn)\n",
    "test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)\n",
    "\n",
    "print(\"Training set accuracy: {accuracy}\".format(**train_eval_result))\n",
    "print(\"Test set accuracy: {accuracy}\".format(**test_eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visually check the confusion matrix to understand the distribution of misclassifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Behzad\\AppData\\Local\\Temp\\tmplgx5pgbr\\model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Behzad\\AppData\\Local\\Temp\\tmplgx5pgbr\\model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'True')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_predictions(estimator, input_fn):\n",
    "    return [x[\"class_ids\"][0] for x in estimator.predict(input_fn=input_fn)]\n",
    "\n",
    "LABELS = [\n",
    "    \"negative\", \"positive\"\n",
    "]\n",
    "\n",
    "# Create a confusion matrix on training data.\n",
    "with tf.Graph().as_default():\n",
    "    cm = tf.compat.v2.math.confusion_matrix(train_df[\"polarity\"], \n",
    "         get_predictions(estimator, predict_train_input_fn))\n",
    "    with tf.compat.v1.Session() as session:\n",
    "         cm_out = session.run(cm)\n",
    "\n",
    "# Normalize the confusion matrix so that each row sums to 1.\n",
    "cm_out = cm_out.astype(float) / cm_out.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "sns.heatmap(cm_out, annot=True, xticklabels=LABELS, yticklabels=LABELS);\n",
    "plt.xlabel(\"Predicted\");\n",
    "plt.ylabel(\"True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " we can improve the accuracy by tuning the meta-parameters like the learning rate or the number of steps, especially if we use a different module. A validation set is very important if we want to get any reasonable results, because it is very easy to set-up a model that learns to predict the training data without generalizing well to the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2: LSTM and Logisitc Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this run through, we first build a corpus preprocessing to remove punctuation and stop words. Then, we implement an LSTM using keras to train a model. Obviously, LSTM is an overkill for a tiny dataset like this, however, this will lay a baseline to show how a much simpler model can achieve a similar accuracy (i.e. Logistic Regression). In addition, we analyze both TF-IDF and CountVectorization with bigrams and unigrams as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\envs\\py36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.decomposition import PCA\n",
    "import glob\n",
    "import tensorflow.keras.preprocessing.text as Preprocess\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we try to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(path, label):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    filenames = glob.glob(path + \"*.txt\")\n",
    "    \n",
    "    for filename in filenames:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            x.append(file.read())\n",
    "        y.append(label)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "x, y = load_dataset(\"aclImdb/train/pos/\", 1)\n",
    "x_train.extend(x)\n",
    "y_train.extend(y)\n",
    "\n",
    "x, y = load_dataset(\"aclImdb/train/neg/\", 0)\n",
    "x_train.extend(x)\n",
    "y_train.extend(y)\n",
    "\n",
    "x, y = load_dataset(\"aclImdb/test/pos/\", 1)\n",
    "x_test.extend(x)\n",
    "y_test.extend(y)\n",
    "\n",
    "x, y = load_dataset(\"aclImdb/test/neg/\", 0)\n",
    "x_test.extend(x)\n",
    "y_test.extend(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the dataset, we start by removing some stop words from the dataset. We do this by using NLTK's base stop word dataset. Just as a preprocessing step, we divide the reviews into word sequences as well. This is both for convenience to remove stop words and later on build our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ws = [Preprocess.text_to_word_sequence(review) for review in x_train]\n",
    "x_test_ws = [Preprocess.text_to_word_sequence(review) for review in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(data):\n",
    "    for i in range(len(data)):\n",
    "        data[i] = [word for word in data[i] if word not in stop_words]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ws = remove_stopwords(x_train_ws)\n",
    "x_test_ws = remove_stopwords(x_test_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next build the corpus and get the tokenized words converted to represent a unique integer index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_re = [' '.join(i) for i in x_train_ws]\n",
    "x_test_re = [' '.join(i) for i in x_test_ws]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', max_features=8000)\n",
    "x_train_v = vectorizer.fit_transform(x_train_re)\n",
    "unique_words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train_i = []\n",
    "x_test_i = []\n",
    "\n",
    "for review in x_train_ws:\n",
    "    x_train_i.append([vectorizer.vocabulary_[word]+1 for word in review if word in vectorizer.vocabulary_])\n",
    "\n",
    "for review in x_test_ws:\n",
    "    x_test_i.append([vectorizer.vocabulary_[word]+1 for word in review if word in vectorizer.vocabulary_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "source": [
    "##### LSTM\n",
    "Before feeding the data into neural network, we have to truncate or pad the reviews to make sure they are of certain length. This is done by analyzing the dataset to visualize the review lengths, and thereby picking fixed length. For our classifier, we decided to pick a length of 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lengths = [len(x) for x in x_train_i]\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "plt.hist(data_lengths, bins=100)\n",
    "plt.title(\"Review length\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_truncated = keras.preprocessing.sequence.pad_sequences(x_train_i, maxlen=300)\n",
    "x_test_truncated = keras.preprocessing.sequence.pad_sequences(x_test_i, maxlen=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 300)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "x_train_n = np.array(x_train_truncated)\n",
    "y_train_n = np.array(y_train)\n",
    "x_test_n = np.array(x_test_truncated)\n",
    "y_test_n = np.array(y_test)\n",
    "\n",
    "print(x_train_n.shape)\n",
    "print(y_train_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 128)         1024128   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,155,841\n",
      "Trainable params: 1,155,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(vectorizer.vocabulary_)+1, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21250 samples, validate on 3750 samples\n",
      "Epoch 1/3\n",
      "21250/21250 [==============================] - 146s 7ms/sample - loss: 0.4217 - accuracy: 0.8084 - val_loss: 0.3967 - val_accuracy: 0.8355\n",
      "Epoch 2/3\n",
      "21250/21250 [==============================] - 143s 7ms/sample - loss: 0.2841 - accuracy: 0.8893 - val_loss: 0.3203 - val_accuracy: 0.8683\n",
      "Epoch 3/3\n",
      "21250/21250 [==============================] - 141s 7ms/sample - loss: 0.2210 - accuracy: 0.9144 - val_loss: 0.7037 - val_accuracy: 0.7688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1704bb03748>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_callback = ModelCheckpoint('imdb.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "model.fit(x_train_n, y_train_n, batch_size=64, shuffle=True,\n",
    "          validation_split=0.15, epochs=3, callbacks=[ckpt_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('imdb.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss :  0.3336026476383209\n",
      "Test accuracy :  0.8598\n",
      "Train loss :  0.19860350970745086\n",
      "Train accuracy :  0.92716\n"
     ]
    }
   ],
   "source": [
    "(loss, accuracy) = model.evaluate(x_test_n, y_test_n, verbose=0, batch_size=128)\n",
    "\n",
    "print(\"Test loss : \", loss)\n",
    "print(\"Test accuracy : \", accuracy)\n",
    "\n",
    "(loss, accuracy) = model.evaluate(x_train_n, y_test_n, verbose=0, batch_size=128)\n",
    "\n",
    "print(\"Train loss : \", loss)\n",
    "print(\"Train accuracy : \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model achieved a test accuracy of 85.98% and training accuracy of 92.71%. Leaving it running for longer yielded a much lower training loss than validation loss. Therefore, we decided to halt the model only after two epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first use CountVectorization and then TF-IDF with unigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression (Count vectorizer, Unigram) train accuracy :  0.98576\n",
      "Logistic regression (Count vectorizer, Unigram) test accuracy :  0.85044\n"
     ]
    }
   ],
   "source": [
    "x_train_v = vectorizer.transform(x_train_re)\n",
    "x_test_v = vectorizer.transform(x_test_re)\n",
    "\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(x_train_v, y_train)\n",
    "\n",
    "accuracy = logistic_regression.score(x_train_v, y_train)\n",
    "print(\"Logistic regression (Count vectorizer, Unigram) train accuracy : \", accuracy)\n",
    "\n",
    "accuracy = logistic_regression.score(x_test_v, y_test)\n",
    "print(\"Logistic regression (Count vectorizer, Unigram) test accuracy : \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression (Count vectorizer, Unigram) train accuracy :  0.93656\n",
      "Logistic regression (TfIdf, Unigram) test accuracy :  0.88264\n"
     ]
    }
   ],
   "source": [
    "idf_vectorizer = TfidfVectorizer(analyzer='word')\n",
    "x_train_idf = idf_vectorizer.fit_transform(x_train_re)\n",
    "x_test_idf = idf_vectorizer.transform(x_test_re)\n",
    "\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(x_train_idf, y_train)\n",
    "\n",
    "accuracy = logistic_regression.score(x_train_idf, y_train)\n",
    "print(\"Logistic regression (TfIdf, Unigram) train accuracy : \", accuracy)\n",
    "\n",
    "accuracy = logistic_regression.score(x_test_idf, y_test)\n",
    "print(\"Logistic regression (TfIdf, Unigram) test accuracy : \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we include Bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression (Count vectorizer, Bigram) train accuracy :  1.0\n",
      "Logistic regression (Count vectorizer, Bigram) test accuracy :  0.88644\n"
     ]
    }
   ],
   "source": [
    "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(1, 2))\n",
    "\n",
    "x_train_v = vectorizer2.fit_transform(x_train_re)\n",
    "x_test_v = vectorizer2.transform(x_test_re)\n",
    "\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(x_train_v, y_train)\n",
    "\n",
    "accuracy = logistic_regression.score(x_train_v, y_train)\n",
    "print(\"Logistic regression (Count vectorizer, Bigram) train accuracy : \", accuracy)\n",
    "\n",
    "accuracy = logistic_regression.score(x_test_v, y_test)\n",
    "print(\"Logistic regression (Count vectorizer, Bigram) test accuracy : \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression (TfIdf, Bigram) train accuracy :  0.96264\n",
      "Logistic regression (TfIdf, Bigram) accuracy :  0.88012\n"
     ]
    }
   ],
   "source": [
    "idf_vectorizer2 = TfidfVectorizer(analyzer='word', ngram_range=(1, 2))\n",
    "x_train_idf = idf_vectorizer2.fit_transform(x_train_re)\n",
    "x_test_idf = idf_vectorizer2.transform(x_test_re)\n",
    "\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(x_train_idf, y_train)\n",
    "\n",
    "accuracy = logistic_regression.score(x_train_idf, y_train)\n",
    "print(\"Logistic regression (TfIdf, Bigram) train accuracy : \", accuracy)\n",
    "\n",
    "accuracy = logistic_regression.score(x_test_idf, y_test)\n",
    "print(\"Logistic regression (TfIdf, Bigram) accuracy : \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding bigrams improved the accuracy for the count vectorization but not for TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is the final comparison and the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_acc = [0.92716, 0.98576, 0.93656, 1.0, 0.96264]\n",
    "test_acc = [0.8598, 0.85044, 0.88264, 0.88644, 0.88012]\n",
    "labels = ['LSTM', 'CV-UNIGRAM+LR', 'TF-IDF-UNIGRAM+LR', 'CV-BIGRAM+LR', 'TF-IDF-BIGRAM+LR']\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "figure, ax = plt.subplots(figsize=(12,12))\n",
    "rects1 = ax.bar(x - width/2, train_acc, width, label='Train')\n",
    "rects2 = ax.bar(x + width/2, test_acc, width, label='Test')\n",
    "\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracies for 5 models')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the figure, a simpler model also achieves a similar accuracy with a little bit more complex model. In fact, TF-IDF with both Unigram and Bigram seems to be doing better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 3: CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the report, we examin Convolutional Neural Network (CNN) to try to predict the outcome of a movie review as a \"Positive\" or a \"Negative\" review. Please make sure you have the data set (consisting of positive reviews and negative reviews in the described foldres)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the first step, we assing the paths of the different sets of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "train_path_pos = './Data/Train/pos/'\n",
    "train_path_neg = './Data/Train/neg/'\n",
    "test_path_pos = './Data/Test/pos/'\n",
    "test_path_neg = './Data/Test/neg/'\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we try to construct data structures appropriate for learning methods (a data frame) with the text (i.e., reviews) and the label (i.e., positive labeled as `1` and negative labeled as `0`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random as rd\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "def read_all_files(path: str, label: int) -> dict:\n",
    "    \"\"\"reading all the txt files into a dictionary including the labels\"\"\"\n",
    "    folder = os.listdir(path)\n",
    "    res = {}\n",
    "    for file in folder:\n",
    "        text = open(path + file).readline().lower()\n",
    "        res[text] = label\n",
    "    return res\n",
    "\n",
    "def concat_all(dict_1: dict, dict_2: dict) -> DataFrame:\n",
    "    \"\"\"creating a data frame\"\"\"\n",
    "    temp = dict()\n",
    "    temp.update(dict_1)\n",
    "    temp.update(dict_2)\n",
    "    keys = list(temp.keys())\n",
    "    rd.shuffle(keys)\n",
    "    target = []\n",
    "    for key in keys:\n",
    "        target.append(temp[key])\n",
    "    ans = DataFrame({'text': keys, 'label': target})\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the functions defined above, we can now create the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the most difficult thing about this movie is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when i rented \"unhinged\", i was expecting a go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this film was terrible. ok, my favourite film ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wizards of the lost kingdom is a movie about a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my goodness is this movie bad. i was totally m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  the most difficult thing about this movie is t...      0\n",
       "1  when i rented \"unhinged\", i was expecting a go...      0\n",
       "2  this film was terrible. ok, my favourite film ...      0\n",
       "3  wizards of the lost kingdom is a movie about a...      1\n",
       "4  my goodness is this movie bad. i was totally m...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_pos = read_all_files(path=train_path_pos, label=1)\n",
    "dict_neg = read_all_files(path=train_path_neg, label=0)\n",
    "train_data = concat_all(dict_pos, dict_neg)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>man with the screaming brain certainly isn't a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you don't review james bond movies, you evalua...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hilarious and low-budget comedy at it's best. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i haven't seen this in years but when i was ab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>most predicable movie i've ever seen...extreme...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  man with the screaming brain certainly isn't a...      1\n",
       "1  you don't review james bond movies, you evalua...      1\n",
       "2  hilarious and low-budget comedy at it's best. ...      1\n",
       "3  i haven't seen this in years but when i was ab...      1\n",
       "4  most predicable movie i've ever seen...extreme...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_pos = read_all_files(path=test_path_pos, label=1)\n",
    "dict_neg = read_all_files(path=test_path_neg, label=0)\n",
    "test_data = concat_all(dict_pos, dict_neg)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the data structure for training and testing sets, we need a way to process the natural language. One can do that using Natural Language Tool-Kit (`nltk`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "word_table = str.maketrans('', '', punctuation)\n",
    "\n",
    "def clean_text(text: str) -> list:\n",
    "    \"\"\"cleaning given text using natural language processing\"\"\"\n",
    "    word_list = word_tokenize(text)\n",
    "    word_list = [w for w in word_list if w.isalpha()]\n",
    "    word_list = [w.translate(word_table) for w in word_list]\n",
    "    word_list = [w for w in word_list if not w in stop_words]\n",
    "    word_list = [w for w in word_list if len(w) > 1]\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the methods we defined above, we can process the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24904"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = train_data['text']\n",
    "rev_train = []\n",
    "for text in text_list:\n",
    "    words = clean_text(text=text)\n",
    "    rev_train.append(words)\n",
    "len(rev_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process the test set in the same manner we processed the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24801"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = test_data['text']\n",
    "rev_test = []\n",
    "for text in text_list:\n",
    "    words = clean_text(text=text)\n",
    "    rev_test.append(words)\n",
    "len(rev_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a data frame to hold the length of each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_length(rev_list: list) -> DataFrame:\n",
    "    \"\"\"creating a data frame from the length of each review\"\"\"\n",
    "    length = DataFrame([len(rev) for rev in rev_list])\n",
    "    length.columns = ['length']\n",
    "    return length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see the length of each review in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   length\n",
       "0      46\n",
       "1     114\n",
       "2     118\n",
       "3      42\n",
       "4     237"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_train = rev_length(rev_train)\n",
    "len_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a look at the describtion of the train set lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24904.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>118.513974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>89.553006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>145.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1409.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             length\n",
       "count  24904.000000\n",
       "mean     118.513974\n",
       "std       89.553006\n",
       "min        4.000000\n",
       "25%       63.000000\n",
       "50%       88.000000\n",
       "75%      145.000000\n",
       "max     1409.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also the length of each review in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   length\n",
       "0     137\n",
       "1     529\n",
       "2      63\n",
       "3     128\n",
       "4      85"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_test = rev_length(rev_test)\n",
    "len_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the test set describtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24801.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>115.826338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>87.356121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>86.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>141.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1121.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             length\n",
       "count  24801.000000\n",
       "mean     115.826338\n",
       "std       87.356121\n",
       "min        3.000000\n",
       "25%       62.000000\n",
       "50%       86.000000\n",
       "75%      141.000000\n",
       "max     1121.000000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, most of the data lay before the length 141 (75%). We have to define `max_length` to consider the review for the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 256\n",
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a minimum length for the test set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_test = 256\n",
    "max_length_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a dictionary of the words and their frequency for further assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_freq(words_list: list) -> dict:\n",
    "    \"\"\"creating a dictionary of words frequency\"\"\"\n",
    "    freq = {}\n",
    "    for w in words_list:\n",
    "        if w in freq:\n",
    "            freq[w] += 1\n",
    "        else:\n",
    "            freq[w] = 1\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function above, we can count the words in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71262"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools as itr\n",
    "\n",
    "\n",
    "words_train = itr.chain.from_iterable(rev_train)\n",
    "freq_train = create_freq(words_list=words_train)\n",
    "len(freq_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same manner, we can count the words in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70355"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_test = itr.chain.from_iterable(rev_test)\n",
    "freq_test = create_freq(words_list=words_test)\n",
    "len(freq_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most frequent words are important. Therefore, we need to sort the dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator as op\n",
    "\n",
    "\n",
    "freq_train_list = list(reversed(sorted(freq_train.items(), key=op.itemgetter(1))))\n",
    "freq_test_list = list(reversed(sorted(freq_test.items(), key=op.itemgetter(1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having the reviews in the form of \"bag of words\", we need to assing them to numbers as well (e.g., most common word, second most common word, etc.) and we only keep count up to `cap` different words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = 7000\n",
    "word_id_train = dict()\n",
    "id_word_train = dict()\n",
    "word_id_test = dict()\n",
    "id_word_test = dict()\n",
    "for i in range(0, cap):\n",
    "    word_id_train[freq_train_list[i][0]] = i\n",
    "    id_word_train[i] = freq_train_list[i][0]\n",
    "    word_id_test[freq_test_list[i][0]] = i\n",
    "    id_word_test[i] = freq_test_list[i][0]\n",
    "\n",
    "len(word_id_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the neural network, we need to create features based on the frequenct words that appear in the context of each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq_data(rev: list) -> list:\n",
    "    \"\"\"getting the frequency list of the reviews\"\"\"\n",
    "    ans = []\n",
    "    for word in rev:\n",
    "        if word in word_id_train:\n",
    "            ans.append(word_id_train[word])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the function above, we can create `x_set` and `y_set` for training purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_set = []\n",
    "y_set = []\n",
    "\n",
    "for i in range(0, len(rev_train)):\n",
    "    rev = get_freq_data(rev=rev_train[i])\n",
    "    if len(rev) <= max_length_train:\n",
    "        x_set.append(rev)\n",
    "        y_set.append(train_data['label'][i])\n",
    "x_set = np.asarray(x_set)\n",
    "y_set = np.asarray(y_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since not all the reviews have the same size, we need to pad them so the appear in the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23611, 256), (23611,))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "x_set = sequence.pad_sequences(x_set, maxlen=max_length, value=0)\n",
    "(x_set.shape, y_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to repoeat the process for the testing set as weel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23654, 256), (23654,))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "# rev_small_test = rd.sample(rev_test, 5000)\n",
    "\n",
    "for i in range(0, len(rev_test)):\n",
    "    rev = get_freq_data(rev=rev_test[i])\n",
    "    if len(rev) <= max_length_test:\n",
    "        x_test.append(rev)\n",
    "        y_test.append(test_data['label'][i])\n",
    "x_test = np.asarray(x_test)\n",
    "y_test = np.asarray(y_test)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_length, value=0)\n",
    "(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preparing the data for our mode, we can define the model using `keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 256, 32)           224000    \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 256, 128)          12416     \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 256, 64)           24640     \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 256, 32)           4128      \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 256, 16)           1040      \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               409700    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 676,025\n",
      "Trainable params: 676,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Dropout,Conv1D,Flatten\n",
    "from keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(cap, 32, input_length=max_length_train))\n",
    "model.add(Conv1D(128, 3, padding='same'))\n",
    "model.add(Conv1D(64, 3, padding='same'))\n",
    "model.add(Conv1D(32, 2, padding='same'))\n",
    "model.add(Conv1D(16, 2, padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last layers, we chose `sigmoid` as the activation function, since we are classifying the reviews as positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function is defined as `binary_crossentropy` and our metric to examin is `accuracy`. It is time to run the model on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "23611/23611 [==============================] - 33s 1ms/step - loss: 0.4073 - accuracy: 0.7976\n",
      "Epoch 2/5\n",
      "23611/23611 [==============================] - 32s 1ms/step - loss: 0.2319 - accuracy: 0.9089\n",
      "Epoch 3/5\n",
      "23611/23611 [==============================] - 32s 1ms/step - loss: 0.1577 - accuracy: 0.9418\n",
      "Epoch 4/5\n",
      "23611/23611 [==============================] - 31s 1ms/step - loss: 0.0801 - accuracy: 0.9741\n",
      "Epoch 5/5\n",
      "23611/23611 [==============================] - 31s 1ms/step - loss: 0.0475 - accuracy: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x13386bb38>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_set, y_set, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23654/23654 [==============================] - 8s 320us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8424367904663086"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=64)\n",
    "score[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, after `epochs = 5`, the accuracy on the training data set is `% 98.48`, and the accuracy on the testing data set is `% 84.24`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the summary, we showed that:\n",
    "\n",
    "1) `DNN` method leads to `% 81.90` accuracy on the training data set and `% 79.79` on the testing data set. We showed that `DNN` method can achieve reletively low error predictions on the future data.\n",
    "\n",
    "2) `LSTM and Logistic Regression` can get up to `% 88` accuracy on the test data. As our second method of prediction, we examined `LSTM` and `LR` (with `CV`, and `TFIDF`), showing that it can acheive an average of `% 86` accuracy on the testing data set.\n",
    "\n",
    "3) As our last method, we tried to predict the movie review class using `CNN`, leading to `% 98.48` accuracy on the training data set and `% 84.24` on the testing data set.\n",
    "\n",
    "To sum it up, machine learning approaches that we chose to examin here can predict the future data on the movie reviews accuratly.\n",
    "\n",
    "For each section (method), we try to have an independent preprocessing of the data to make sure that any changes do not affect the future prediction of another method. Also, independent preprocessing enabled us to work on rach method (model) independently."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
